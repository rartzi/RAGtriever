[vault]
root = "/path/to/vault"
ignore = [
    ".git/**",
    ".obsidian/cache/**",
    "**/.DS_Store",
    "**/~$*",           # Office temp files (Word, Excel, PowerPoint)
    "**/.~lock.*",      # LibreOffice lock files
    "**/~*.tmp",        # Generic temp files
    "**/*.swp",         # Vim swap files
    "**/*.bak"          # Backup files
]

[index]
dir = "~/.ragtriever/indexes/myvault"
extractor_version = "v1"
chunker_version = "v1"

[embeddings]
provider = "sentence_transformers"
model = "BAAI/bge-small-en-v1.5"
batch_size = 32
device = "cpu"  # cpu|cuda|mps
# Set to true to use cached models only (no HuggingFace downloads)
# Can also be controlled via HF_OFFLINE_MODE environment variable
# IMPORTANT: Run once with offline_mode=false to download the model first,
# then switch to offline_mode=true. Check cached models: ls ~/.cache/huggingface/hub/
offline_mode = true

[image_analysis]
provider = "tesseract"  # tesseract|gemini|vertex_ai|off
# Automatically extracts and analyzes:
# - Images embedded in PDFs (extracted via PyMuPDF)
# - Images in PowerPoint slides (extracted via python-pptx)
# - Images referenced in Markdown (![](path) and ![[image]])
# - Standalone image files (.png, .jpg, .jpeg, .webp, .gif)
#
# For tesseract: requires pytesseract and tesseract-ocr installed on system
# For gemini: set GEMINI_API_KEY env var or gemini_api_key below
# For vertex_ai: configure [vertex_ai] section below
# gemini_api_key = ""
gemini_model = "gemini-2.0-flash"

# Vertex AI configuration (for provider = "vertex_ai")
[vertex_ai]
# project_id = "your-gcp-project-id"  # or set GOOGLE_CLOUD_PROJECT env var
# location = "global"  # or us-central1, us-east4, etc. depending on model availability
# credentials_file = "/path/to/service-account.json"  # or set GOOGLE_APPLICATION_CREDENTIALS env var
# model = "gemini-2.0-flash-exp"  # available models depend on region

[retrieval]
k_vec = 40
k_lex = 40
top_k = 10
use_rerank = false

[mcp]
transport = "stdio"
